{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programación en Paralelo\n",
    "\n",
    "* ### Distribuir funciones de cálculo entre distintos procesadores\n",
    "* ### Colectar los resultados obtenidos en cada procesador\n",
    "* ### Sintetizar con esos resultados parciales, un resultado significativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pase de mensajes entre procesadores\n",
    "\n",
    "## M P I = Message Passing Interface\n",
    "\n",
    "* ### Es una especificación, no es una librería de funciones.\n",
    "* ### Muchas organizaciones se ponen de acuerdo\n",
    "* ### Diseñada para implementar modelos de programación en paralelo\n",
    "* ### Los datos se mueven de un espacio de memoria de un proceso al espacio de memoria de otro proceso\n",
    "* ### Con MPI se pueden escribir aplicaciones que requieren pasar mensajes entre ellos\n",
    "* ### La especificación MPI tiene varias versiones, hay que tener cuidado con esto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de programación\n",
    "\n",
    "* ### Originalmente diseñada para arquitecturas de memoria distribuída\n",
    "![Memoria Distribuída](distributed_mem.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Evolución arquitectural  SMP (Symmetric multiprocessing) con memoria compartida\n",
    "![Sistemas  híbridos](hybrid_mem.gif)\n",
    "\n",
    "* ### MPI soporta modelos:\n",
    "  * Distribuidos\n",
    "  * Compartidos\n",
    "  * Híbridos\n",
    "  \n",
    "* ### El modelo de programación es en memoria distribuída, independiente de la arquitectura física\n",
    "* ### El paralelismo es explícito: el programador identifica el paralelismo y es el responsable de implementar el paralelismo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistemas de memoria distribuída\n",
    "\n",
    "* ### Cada procesador tiene su propia memoria\n",
    "* ### Una red de datos conecta todo los procesadores\n",
    "\n",
    "## Programación por pase de mensajes\n",
    "\n",
    "* ### Un programa en paralelo se descompone en procesadores, llamados ranks\n",
    "* ### Cada rank mantiene una parte de los datos de programas en su memoria\n",
    "* ### La comunicación entre ranks se explicita con mensajes entre ellos\n",
    "* ### Los mensajes responden a FIFO\n",
    "\n",
    "## Un solo programa, múltiples datos\n",
    "\n",
    "* ### Todos los procesadores corren el mismo programa\n",
    "* ### Todos los programas empiezan simultaneamente\n",
    "* ### Comunicaciones entre nodos\n",
    "  * #### Mensajes punto a punto\n",
    "  * #### Operaciones de comunicación colectiva (ej. broadcast)\n",
    "  \n",
    "  \n",
    "## Principales características del pase de mensaje\n",
    "\n",
    "* ### Simple: operaciones de comunicación típicas (Send, Receive)\n",
    "* ### General: puede ser implementado en la mayoría de las arquitecturas paralelo}\n",
    "* ### Performante: una implementación se puede adaptar a un hardware particular\n",
    "* ### Escalable: el mismo programa se puede usar en sistemas más grandes\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPI Ranks\n",
    "\n",
    "* ### Tienen su propia memoria\n",
    "* ### Cada  rank tiene un único número de identificación\n",
    "* ### Los ranks se numeran secuencialmente: [0, N-1].\n",
    "\n",
    "![mpi ranks](mpi_ranks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comunicadores MPI\n",
    "\n",
    "\n",
    "\n",
    "* ### Grupo de ranks entre los cuales un nodo del grupo se puede comunicar\n",
    "* ### COMM_WORLD es un comunicador que contiene a todos los ranks (nodos) del sistema\n",
    "\n",
    "![comm world](comm_world.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Razones para usar MPI\n",
    "\n",
    "* ### Standard\n",
    "* ### Portable\n",
    "* ### Optimizable\n",
    "* ### Funcional\n",
    "* ### Disponible (C, Fortran, python, c++, otros ..)\n",
    "* ### Lenguaje standard de facto para cálculo en paralelo en computadoras alta performance\n",
    "* ### Es un modelo simple de comunicaciones entre procesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estructura de Programa\n",
    "\n",
    "![Sistemas  híbridos](prog_structure.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python: mpi4py\n",
    "\n",
    "* ### Una de las mejores implementaciones de MPI en python\n",
    "* ### Cumple con la especificación MPI-2 (hay MPI-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HelloWorld.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parallel Hello World\n",
    "\"\"\"\n",
    "#\n",
    "# Los includes\n",
    "#\n",
    "from mpi4py import MPI\n",
    " \n",
    "#\n",
    "# Inicializacion\n",
    "#\n",
    "size = MPI.COMM_WORLD.Get_size()\n",
    "rank = MPI.COMM_WORLD.Get_rank()\n",
    "name = MPI.Get_processor_name()\n",
    "\n",
    "#\n",
    "# El programa\n",
    "#\n",
    "print(\n",
    "    \"Hello, World! I am process %d of %d on %s.\"\n",
    "    % (rank, size, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecución\n",
    "\n",
    "\n",
    "    > mpiexec -n 4  python helloworld.py\n",
    "    \n",
    "### Salida\n",
    "\n",
    "    Hello, World! I am process 2 of 4 on sheldon.dcap.cnea.gov.ar.\n",
    "    Hello, World! I am process 3 of 4 on sheldon.dcap.cnea.gov.ar.\n",
    "    Hello, World! I am process 1 of 4 on sheldon.dcap.cnea.gov.ar.\n",
    "    Hello, World! I am process 0 of 4 on sheldon.dcap.cnea.gov.ar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseParallel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Parallel baseParallel \n",
    "\"\"\"\n",
    "\n",
    "#\n",
    "# Los include\n",
    "#\n",
    "from mpi4py import MPI\n",
    "\n",
    "#\n",
    "# La inicializacion\n",
    "#\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "#\n",
    "# Definicion de la funcion\n",
    "#\n",
    "def func(rank):\n",
    "    print (\"func ejecuto en %d\" % (rank))\n",
    "\n",
    "#\n",
    "# Ejecucion de la funcion\n",
    "#\n",
    "func(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecución\n",
    "\n",
    "\n",
    "    > mpiexec -n 4  python baseParallel.py\n",
    "\n",
    "### Salida\n",
    "\n",
    "    func ejecuto en 1\n",
    "    func ejecuto en 2\n",
    "    func ejecuto en 0\n",
    "    func ejecuto en 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parallelSum.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Parallel parallelSum\n",
    "\"\"\"\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "#\n",
    "# Los datos para operar\n",
    "#\n",
    "a = [1,2,4,5]\n",
    "b = [10,20,40,50]\n",
    "\n",
    "\n",
    "def func(rank):\n",
    "    c = a[rank] + b[rank]\n",
    "    print (\"ejecuto en %d %d\" % (rank, c))\n",
    "\n",
    "\n",
    "func(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecución\n",
    "\n",
    "    mpiexec -n 4 python parallelSum.py\n",
    "\n",
    "### Salida\n",
    "    ejecuto en 3 55\n",
    "    ejecuto en 0 11\n",
    "    ejecuto en 1 22\n",
    "    ejecuto en 2 44\n",
    "    \n",
    "### Observar el orden de ejecución de los nodos    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parallelSum_B.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Parallel parallelSum\n",
    "\"\"\"\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "a = [1,2,4,5]\n",
    "b = [10,20,40,50]\n",
    "\n",
    "def func(rank):\n",
    "    c = a[rank] + b[rank]\n",
    "    print (\"ejecuto en %d %d\" % (rank, c))\n",
    "    return c\n",
    "\n",
    "\n",
    "S = func(rank)\n",
    "\n",
    "print( \"nodo %d suma %d\"%(rank, S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecución\n",
    "\n",
    "    mpiexec -n 4 python parallelSum_B.py\n",
    "    \n",
    "### Salida\n",
    "\n",
    "    ejecuto en 2 44\n",
    "    nodo 2 suma 44\n",
    "    ejecuto en 3 55\n",
    "    nodo 3 suma 55\n",
    "    ejecuto en 0 11\n",
    "    nodo 0 suma 11\n",
    "    ejecuto en 1 22\n",
    "    nodo 1 suma 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parallelSum_C.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Parallel parallelSum\n",
    "\"\"\"\n",
    "\n",
    "from mpi4py import MPI\n",
    "from mpi4py.MPI import ANY_SOURCE\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "a = [1,2,4,5]\n",
    "b = [10,20,40,50]\n",
    "total = 0\n",
    "\n",
    "def func(rank):\n",
    "    c = a[rank] + b[rank]\n",
    "    print (\"ejecuto en %d %d\" % (rank, c))\n",
    "    return c\n",
    "\n",
    "\n",
    "S = func(rank)\n",
    "\n",
    "if rank == 0:\n",
    "    total = total + S\n",
    "else:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "print (\"total: \", total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecución\n",
    "\n",
    "    mpiexec -n 4 python  parallelSum_C.py\n",
    "\n",
    "### Salida\n",
    "\n",
    "    ejecuto en 0 11\n",
    "    ('total: ', 11)\n",
    "    ejecuto en 1 22\n",
    "    ('total: ', 0)\n",
    "    ejecuto en 2 44\n",
    "    ('total: ', 0)\n",
    "    ejecuto en 3 55\n",
    "    ('total: ', 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parallelSum_D.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Parallel parallelSum\n",
    "\"\"\"\n",
    "\n",
    "from mpi4py import MPI\n",
    "from mpi4py.MPI import ANY_SOURCE\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "a = [1,2,4,5]\n",
    "b = [10,20,40,50]\n",
    "total = 0\n",
    "\n",
    "def func(rank):\n",
    "    c = a[rank] + b[rank]\n",
    "    print (\"ejecuto en %d %d\" % (rank, c))\n",
    "    return c\n",
    "\n",
    "\n",
    "S = func(rank)\n",
    "\n",
    "if rank == 0:\n",
    "    total = total + S\n",
    "else:\n",
    "    pass\n",
    "\n",
    "\n",
    "if rank == 0:\n",
    "    print (\"total: \", total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecución    \n",
    "    \n",
    "    mpiexec -n 4 python  parallelSum_D.py\n",
    "\n",
    "\n",
    "### Salida\n",
    "    ejecuto en 2 44\n",
    "    ejecuto en 3 55\n",
    "    ejecuto en 0 11\n",
    "    ('total: ', 11)\n",
    "    ejecuto en 1 22\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parallelSum_E.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Parallel parallelSum_E\n",
    "\"\"\"\n",
    "\n",
    "#\n",
    "#   Las librerias que vamos a usar\n",
    "#\n",
    "from mpi4py import MPI\n",
    "from mpi4py.MPI import ANY_SOURCE\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "# Inicio de MPI\n",
    "#\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "#\n",
    "# Los datos del problema\n",
    "#\n",
    "a = np.asarray([1,2,4,5])\n",
    "b = np.asarray([10,20,40,50])\n",
    "total = 0\n",
    "\n",
    "#\n",
    "# La memoria para transmitir y recibir resultados\n",
    "#\n",
    "suma = np.zeros(1)\n",
    "recv_buffer = np.zeros(1)\n",
    "\n",
    "#\n",
    "# La funcion a ejecutar \n",
    "#\n",
    "def func(rank):\n",
    "    c = a[rank] + b[rank]\n",
    "    print (\"ejecuto en %d %d\" % (rank, c))\n",
    "    return c\n",
    "\n",
    "#\n",
    "# la ejecucion de la funcion\n",
    "#\n",
    "suma[0] = func(rank)\n",
    "\n",
    "\n",
    "#\n",
    "# Concentracion de los resultados\n",
    "#\n",
    "if rank == 0:\n",
    "    total = total + suma[0]\n",
    "    # el nodo 0 espera los resultados\n",
    "    for i in range(1, size):\n",
    "        comm.Recv(recv_buffer, ANY_SOURCE)\n",
    "        total += recv_buffer[0]\n",
    "else:\n",
    "    # el resto de los nodos transmiten el resultado S \n",
    "    comm.Send(suma)\n",
    "\n",
    "\n",
    "if rank == 0:\n",
    "        print (\"total: \", total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecución\n",
    "\n",
    "    mpiexec -n 4 python  parallelSum_E.py\n",
    "    \n",
    "#### Salida\n",
    "\n",
    "    ejecuto en 0 11\n",
    "    ejecuto en 2 44\n",
    "    ejecuto en 3 55\n",
    "    ejecuto en 1 22\n",
    "    ('total: ', 132.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "* Message Passing Interface  [(MPI)](https://computing.llnl.gov/tutorials/mpi/)\n",
    "* Serial to Parallel: Monte Carlo Operation [link](https://www.olcf.ornl.gov/tutorials/monte-carlo-pi/)\n",
    "\n",
    "* A Python Introduction to Parallel Programming with MPI [link](http://materials.jeremybejarano.com/MPIwithPython/index.html)\n",
    "\n",
    "* MPI with MPI4py Introduction [link](http://pythonprogramming.net/learning-use-mpi-python-mpi4py-module/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
